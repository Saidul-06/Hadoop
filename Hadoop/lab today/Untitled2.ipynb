{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87009def",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12908\\4132232756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[1;31m# Handles the creation of plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[1;31m# Data visualization library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m \u001b[1;31m# Machine learning library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;31m# Library for neural networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;31m# Handles the layers of the neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Project: Predict Vehicle Fuel Economy Using a Deep Neural Network\n",
    "# Author: Addison Sears-Collins\n",
    "# Date created: November 3, 2020\n",
    " \n",
    "import pandas as pd # Used for data analysis\n",
    "import pathlib # An object-oriented interface to the filesystem\n",
    "import matplotlib.pyplot as plt # Handles the creation of plots\n",
    "import seaborn as sns # Data visualization library\n",
    "import tensorflow as tf # Machine learning library\n",
    "from tensorflow import keras # Library for neural networks\n",
    "from tensorflow.keras import layers # Handles the layers of the neural network\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Set the data path for the Auto-Mpg data set from the UCI Machine Learning Repository\n",
    "  datasetPath = keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    " \n",
    "  # Set the column names for the data set\n",
    "  columnNames = ['MPG', 'Cylinders','Displacement','Horsepower','Weight',\n",
    "               'Acceleration','Model Year','Origin']\n",
    " \n",
    "  # Import the data set\n",
    "  originalData = pd.read_csv(datasetPath, names=columnNames, na_values = \"?\", \n",
    "                           comment='\\t', sep=\" \", skipinitialspace=True)\n",
    "                          \n",
    "  # Check the data set\n",
    "  # print(\"Original Data Set Excerpt\")\n",
    "  # print(originalData.head())\n",
    "  # print()\n",
    " \n",
    "  # Generate a copy of the data set\n",
    "  data = originalData.copy()\n",
    " \n",
    "  # Count how many NAs each data attribute has\n",
    "  # print(\"Number of NAs in the data set\")\n",
    "  # print(data.isna().sum())\n",
    "  # print()\n",
    " \n",
    "  # Now, let's remove the NAs from the data set\n",
    "  data = data.dropna()\n",
    " \n",
    "  # Perform one-hot encoding on the Origin attribute \n",
    "  # since it is a categorical variable\n",
    "  origin = data.pop('Origin') # Return item and drop from frame\n",
    "  data['USA'] = (origin == 1) * 1.0\n",
    "  data['Europe'] = (origin == 2) * 1.0\n",
    "  data['Japan'] = (origin == 3) * 1.0\n",
    " \n",
    "  # Generate a training data set (80% of the data) and a testing set (20% of the data)\n",
    "  trainingData = data.sample(frac = 0.8, random_state = 0)\n",
    " \n",
    "  # Generate a testing data set\n",
    "  testingData = data.drop(trainingData.index)\n",
    " \n",
    "  # Separate the attributes from the label in both the testing\n",
    "  # and training data. The label is the thing we are trying\n",
    "  # to predit (i.e. miles per gallon 'MPG')\n",
    "  trainingLabelData = trainingData.pop('MPG')\n",
    "  testingLabelData = testingData.pop('MPG')\n",
    "   \n",
    "  # Normalize the data\n",
    "  normalizedTrainingData = normalize(trainingData)\n",
    "  normalizedTestingData = normalize(testingData)\n",
    "  #print(normalizedTrainingData.head()) \n",
    "   \n",
    "  # Generate the neural network\n",
    "  neuralNet = generateNeuralNetwork(trainingData)\n",
    "   \n",
    "  # See a summary of the neural network\n",
    "  # The first layer has 640 parameters \n",
    "    #(9 input values * 64 neurons) + 64 bias values\n",
    "  # The second layer has 4160 parameters \n",
    "    #(64 input values * 64 neurons) + 64 bias values\n",
    "  # The output layer has 65 parameters \n",
    "    #(64 input values * 1 neuron) + 1 bias value\n",
    "  #print(neuralNet.summary())\n",
    "   \n",
    "  EPOCHS = 1000\n",
    "   \n",
    "  # Train the model for a fixed number of epochs\n",
    "  # history.history attribute is returned from the fit() function.\n",
    "  # history.history is a record of training loss values and \n",
    "  # metrics values at successive epochs, as well as validation \n",
    "  # loss values and validation metrics values.\n",
    "  history = neuralNet.fit(\n",
    "    x = normalizedTrainingData, \n",
    "    y = trainingLabelData,\n",
    "    epochs = EPOCHS, \n",
    "    validation_split = 0.2, \n",
    "    verbose = 0,\n",
    "    callbacks = [PrintDot()]\n",
    "  )   \n",
    "   \n",
    "  # Plot the neural network metrics (Training error and validation error)\n",
    "  # Training error is the error when the trained neural network is \n",
    "  #   run on the training data.\n",
    "  # Validation error is used to minimize overfitting. It indicates how\n",
    "  #   well the data fits on data it hasn't been trained on.\n",
    "  #plotNeuralNetMetrics(history)\n",
    "   \n",
    "  # Generate another neural network so that we can use early stopping\n",
    "  neuralNet2 = generateNeuralNetwork(trainingData)\n",
    "   \n",
    "  # We want to stop training the model when the \n",
    "  # validation error stops improving.\n",
    "  # monitor indicates the quantity we want to monitor.\n",
    "  # patience indicates the number of epochs with no improvement after which\n",
    "  # training will terminate.\n",
    "  earlyStopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    " \n",
    "  history2 = neuralNet2.fit(\n",
    "    x = normalizedTrainingData, \n",
    "    y = trainingLabelData,\n",
    "    epochs = EPOCHS, \n",
    "    validation_split = 0.2, \n",
    "    verbose = 0,\n",
    "    callbacks = [earlyStopping, PrintDot()]\n",
    "  )    \n",
    " \n",
    "  # Plot metrics\n",
    "  #plotNeuralNetMetrics(history2) \n",
    "   \n",
    "  # Return the loss value and metrics values for the model in test mode\n",
    "  # The mean absolute error for the predictions should \n",
    "  # stabilize around 2 miles per gallon  \n",
    "  loss, meanAbsoluteError, meanSquaredError = neuralNet2.evaluate(\n",
    "    x = normalizedTestingData,\n",
    "    y = testingLabelData,\n",
    "    verbose = 0\n",
    "  )\n",
    "   \n",
    "  #print(f'\\nMean Absolute Error on Test Data Set = {meanAbsoluteError} miles per gallon')\n",
    "   \n",
    "  # Make fuel economy predictions by deploying the trained neural network on the \n",
    "  # test data set (data that is brand new for the trained neural network).\n",
    "  testingDataPredictions = neuralNet2.predict(normalizedTestingData).flatten()\n",
    "   \n",
    "  # Plot the predicted MPG vs. the true MPG\n",
    "  # testingLabelData are the true MPG values\n",
    "  # testingDataPredictions are the predicted MPG values\n",
    "  #plotTestingDataPredictions(testingLabelData, testingDataPredictions)\n",
    "   \n",
    "  # Plot the prediction error distribution\n",
    "  #plotPredictionError(testingLabelData, testingDataPredictions)\n",
    "   \n",
    "  # Save the neural network in Hierarchical Data Format version 5 (HDF5) format\n",
    "  neuralNet2.save('fuel_economy_prediction_nnet.h5')\n",
    "   \n",
    "  # Import the saved model\n",
    "  neuralNet3 = keras.models.load_model('fuel_economy_prediction_nnet.h5')\n",
    "  print(\"\\n\\nNeural network has loaded successfully...\\n\")\n",
    "   \n",
    "  # Show neural network parameters\n",
    "  print(neuralNet3.summary())\n",
    "   \n",
    "  # Make a prediction using the saved model we just imported\n",
    "  print(\"\\nMaking predictions...\")\n",
    "  testingDataPredictionsNN3 = neuralNet3.predict(normalizedTestingData).flatten()\n",
    "   \n",
    "  # Show Predicted MPG vs. Actual MPG\n",
    "  plotTestingDataPredictions(testingLabelData, testingDataPredictionsNN3) \n",
    "   \n",
    "# Generate the neural network\n",
    "def generateNeuralNetwork(trainingData):\n",
    "  # A Sequential model is a stack of layers where each layer is\n",
    "  # single-input, single-output\n",
    "  # This network below has 3 layers.\n",
    "  neuralNet = keras.Sequential([\n",
    "   \n",
    "    # Each neuron in a layer recieves input from all the \n",
    "    # neurons in the previous layer (Densely connected)\n",
    "    # Use the ReLU activation function. This function transforms the input\n",
    "    # into a node (i.e. summed weighted input) into output  \n",
    "    # The first layer needs to know the number of attributes (keys) in the data set.\n",
    "    # This first and second layers have 64 nodes.\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(trainingData.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(1) # This output layer is a single, continuous value (i.e. Miles per gallon)\n",
    "  ])\n",
    " \n",
    "  # Penalize the update of the neural network parameters that are causing\n",
    "  # the cost function to have large oscillations by using a moving average\n",
    "  # of the square of the gradients and dibiding the gradient by the root of this\n",
    "  # average. Reduces the step size for large gradients and increases \n",
    "  # the step size for small gradients.\n",
    "  # The input into this function is the learning rate.\n",
    "  optimizer = keras.optimizers.RMSprop(0.001)\n",
    "  \n",
    "  # Set the configurations for the model to get it ready for training\n",
    "  neuralNet.compile(loss = 'mean_squared_error',\n",
    "                optimizer = optimizer,\n",
    "                metrics = ['mean_absolute_error', 'mean_squared_error'])\n",
    "  return neuralNet\n",
    "     \n",
    "# Normalize the data set using the mean and standard deviation \n",
    "def normalize(data):\n",
    "  statistics = data.describe()\n",
    "  statistics = statistics.transpose()\n",
    "  return(data - statistics['mean']) / statistics['std']\n",
    " \n",
    "# Plot metrics for the neural network  \n",
    "def plotNeuralNetMetrics(history):\n",
    "  neuralNetMetrics = pd.DataFrame(history.history)\n",
    "  neuralNetMetrics['epoch'] = history.epoch\n",
    "   \n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(neuralNetMetrics['epoch'], \n",
    "           neuralNetMetrics['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "  plt.plot(neuralNetMetrics['epoch'], \n",
    "           neuralNetMetrics['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "   \n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(neuralNetMetrics['epoch'], \n",
    "           neuralNetMetrics['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "  plt.plot(neuralNetMetrics['epoch'], \n",
    "           neuralNetMetrics['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "   \n",
    "# Plot prediction error\n",
    "def plotPredictionError(testingLabelData, testingDataPredictions):\n",
    " \n",
    "  # Error = Predicted - Actual\n",
    "  error = testingDataPredictions - testingLabelData\n",
    "   \n",
    "  plt.hist(error, bins = 50)\n",
    "  plt.xlim([-10,10])\n",
    "  plt.xlabel(\"Predicted MPG - Actual MPG\")\n",
    "  _ = plt.ylabel(\"Count\")\n",
    "  plt.show()\n",
    " \n",
    "# Plot predictions vs. true values\n",
    "def plotTestingDataPredictions(testingLabelData, testingDataPredictions):\n",
    " \n",
    "  # Plot the data points (x, y)\n",
    "  plt.scatter(testingLabelData, testingDataPredictions)\n",
    "   \n",
    "  # Label the axes\n",
    "  plt.xlabel('True Values (Miles per gallon)')\n",
    "  plt.ylabel('Predicted Values (Miles per gallon)')\n",
    " \n",
    "  # Plot a line between (0,0) and (50,50) \n",
    "  point1 = [0, 0]\n",
    "  point2 = [50, 50]\n",
    "  xValues = [point1[0], point2[0]] \n",
    "  yValues = [point1[1], point2[1]]\n",
    "  plt.plot(xValues, yValues) \n",
    "   \n",
    "  # Set the x and y axes limits\n",
    "  plt.xlim(0, 50)\n",
    "  plt.ylim(0, 50)\n",
    " \n",
    "  # x and y axes are equal in displayed dimensions\n",
    "  plt.gca().set_aspect('equal', adjustable='box')\n",
    "   \n",
    "  # Show the plot\n",
    "  plt.show()\n",
    "   \n",
    "   \n",
    "# Show the training process by printing a period for each epoch that completes\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "     \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfb280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
